# -*- coding: utf-8 -*-
"""codereadability_sample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Py16UUgJe-CmTVkOGuVLgsqyXkGBEvf0

INSTALL & IMPORT NECESSARY LIBRARIES
"""

!pip install streamlit
!pip install tensorflow
!pip install --upgrade pyngrok

import numpy as np
import pandas as pd
import re
import ast
import streamlit as st
import math
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error,r2_score, explained_variance_score, accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

"""PREPROCESSING USING THE DATASET - PYTHON"""

# Code and dataset "data_python.csv" based from Maheshwari (2023)
df = pd.read_csv('updated_dataset.csv')

# Remove the "class Solution:/n"
df['python_solutions'] = df['python_solutions'].str.replace(r'^class Solution:\n', '', regex=True)

df.head()

def count_comments(code):
 # Count the number of comments using a regular expression
    comments = re.findall(r'#.*|(\'\'\'[\s\S]*?\'\'\'|\"\"\"[\s\S]*?\"\"\`)|```[\s\S]*?```', code)
    return len(comments)

df['comments'] = df['python_solutions'].apply(count_comments)

def cyclomatic_complexity(code):
    decision_points = len(re.findall(r"(if|elif|while|for)\s+.*:", code, re.IGNORECASE))
    exits = len(re.findall(r"(return|break|continue)\b", code, re.IGNORECASE))
    complexity = decision_points + 1 - exits
    return complexity

df['cyclomatic_complexity'] = df['python_solutions'].apply(lambda x: cyclomatic_complexity(x))

def count_indents(code):
    lines = code.split('\n')
    num_indents = 0
    for line in lines:
        num_indents += line.count('    ')  # Assuming each indent is represented by four spaces
    return num_indents

def calculate_rounded_ratio(row):
    return math.ceil(row['num_of_indents'] / row['num_of_lines'])

def count_loops(code):
    loop_keywords = ['for', 'while', 'if']
    count = sum(code.lower().count(keyword) for keyword in loop_keywords)
    return count

def count_identifiers(code):
    identifiers = [':', '=', '==', '<', '>', ',']
    count = sum(code.lower().count(keyword) for keyword in identifiers)
    return count

"""ADDED ADDITIONAL FEATURES"""
def nesting_depth(code):
    depth = 0
    max_depth = 0
    for line in code.split('\n'):
        if line.strip().startswith(('if ', 'for ', 'while ', 'def ', 'class ')):
            depth += 1
            if depth > max_depth:
                max_depth = depth
        elif line.strip().startswith(('else:', 'elif ')):
            pass  # Do not increase depth for else/elif
        else:
            depth = 0
    return max_depth

df['nesting_depth'] = df['python_solutions'].apply(nesting_depth)

def function_length(code):
    functions = code.split('def ')
    lengths = []
    for func in functions[1:]:  # Skip the first element as it's not a function
        lines = func.split('\n')
        lengths.append(len(lines))
    return max(lengths) if lengths else 0

df['function_length'] = df['python_solutions'].apply(function_length)

def average_variable_name_length(code):
    variables = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', code)
    if not variables:
        return 0
    total_length = sum(len(var) for var in variables)
    return total_length / len(variables)

df['avg_var_name_length'] = df['python_solutions'].apply(average_variable_name_length)

def detect_code_smells(code):
    # Example: Detect long methods (more than 20 lines)
    functions = code.split('def ')
    long_methods = 0
    for func in functions[1:]:
        lines = func.split('\n')
        if len(lines) > 20:
            long_methods += 1
    return long_methods

df['code_smells'] = df['python_solutions'].apply(detect_code_smells)

def whitespace_usage(code):
    lines = code.split('\n')
    blank_lines = sum(1 for line in lines if line.strip() == '')
    return blank_lines

df['whitespace_usage'] = df['python_solutions'].apply(whitespace_usage)

def comment_quality(code):
    comments = re.findall(r'#.*', code)
    if not comments:
        return 0
    total_length = sum(len(comment) for comment in comments)
    return total_length / len(comments)

df['comment_quality'] = df['python_solutions'].apply(comment_quality)

def code_structure(code):
    classes = code.count('class ')
    functions = code.count('def ')
    return classes + functions

df['code_structure'] = df['python_solutions'].apply(code_structure)

def operator_complexity(code):
    complex_ops = ['+=', '-=', '*=', '/=', '%=', '//=', '**=', '&=', '|=', '^=', '>>=', '<<=', '?']
    count = 0
    for op in complex_ops:
        count += code.count(op)
    return count

df['operator_complexity'] = df['python_solutions'].apply(operator_complexity)

def count_imports(code):
    imports = re.findall(r'import \w+', code) + re.findall(r'from \w+ import', code)
    return len(imports)

df['imports'] = df['python_solutions'].apply(count_imports)

# Save the updated dataset (if decided to make more features)
# df.to_csv('updated_dataset.csv', index=False)

"""CNN TRAINING & TESTING"""

# Assuming df is already defined and contains the necessary columns
X = df[['num_of_lines', 'code_length', 'comments', 'cyclomatic_complexity', 'indents', 'loop_count', 'identifiers']]
y = df['readability']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2, random_state=42)

# Reshape the data for CNN (add a sequence dimension)
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)  # Shape: (batch_size, 7, 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)      # Shape: (batch_size, 7, 1)

# Define the enhanced CNN model
model = Sequential()

# Input layer
model.add(Conv1D(filters=128, kernel_size=1, activation='relu', padding='same', input_shape=(X_train.shape[1], 1)))  # kernel_size=1, padding='same'
model.add(BatchNormalization())
model.add(MaxPooling1D(pool_size=1))  # No pooling to avoid shrinking sequence length
model.add(Dropout(0.3))

# Hidden layers
model.add(Conv1D(filters=256, kernel_size=1, activation='relu', padding='same'))  # kernel_size=1, padding='same'
model.add(BatchNormalization())
model.add(MaxPooling1D(pool_size=1))  # No pooling to avoid shrinking sequence length
model.add(Dropout(0.4))

model.add(Conv1D(filters=512, kernel_size=1, activation='relu', padding='same'))  # kernel_size=1, padding='same'
model.add(BatchNormalization())
model.add(MaxPooling1D(pool_size=1))  # No pooling to avoid shrinking sequence length
model.add(Dropout(0.5))

# Flatten and fully connected layers
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.4))

model.add(Dense(64, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.3))

# Output layer for regression
model.add(Dense(1))

# Compile the model
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])

# Callbacks for better training
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[reduce_lr, early_stopping]
)

# Evaluate the model
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error: {mae}')

# Predict readability for user input
user_input = """class Solution:
    def twoSum(self, nums: List[int], target: int) -> List[int]:
        for i in range(len(nums)):
            for j in range(i + 1, len(nums)):
                if (i != j and nums[i] + nums[j] == target):
                    return [i, j]
        return []"""

user_features = np.array([[len(user_input.split('\n')), len(user_input),
                           count_comments(user_input), cyclomatic_complexity(user_input),
                           count_indents(user_input), count_loops(user_input),
                           count_identifiers(user_input)]])

user_features = user_features.reshape(1, user_features.shape[1], 1)  # Reshape to (1, 7, 1)
user_score = model.predict(user_features)
print(f'Predicted Readability Score for User Input: {user_score[0][0]:.2f}')

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate regression metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
explained_variance = explained_variance_score(y_test, y_pred)

print(f'Mean Squared Error (MSE): {mse:.4f}')
print(f'R-squared (RÂ²): {r2:.4f}')
print(f'Explained Variance Score: {explained_variance:.4f}')

# Bin the readability scores into categories (e.g., low, medium, high)
bins = np.linspace(min(y), max(y), 4)  # Create 3 bins
y_binned = np.digitize(y, bins)
y_test_binned = np.digitize(y_test, bins)
y_pred_binned = np.digitize(y_pred, bins)

# Calculate classification metrics
accuracy = accuracy_score(y_test_binned, y_pred_binned)
precision = precision_score(y_test_binned, y_pred_binned, average='weighted')
recall = recall_score(y_test_binned, y_pred_binned, average='weighted')
f1 = f1_score(y_test_binned, y_pred_binned, average='weighted')

print(f'Accuracy: {accuracy:.2f}')
print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')
print(f'F1-score: {f1:.2f}')
