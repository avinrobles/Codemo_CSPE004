# -*- coding: utf-8 -*-
"""CNNmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16_V4g3-ew__QhGtJMPXcN8sF2scENdk3
"""

!pip install pytesseract
!pip install easyocr
!pip install keras-ocr

import tensorflow as tf
print("Tensorflow imported")
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os

gpus = tf.config.experimental.list_physical_devices("GPU")
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu,True)
gpus

data = tf.keras.utils.image_dataset_from_directory('dataset',image_size=(60,40),color_mode="grayscale")

data_iter = data.as_numpy_iterator()
data_iter

batch = data_iter.next()

print(len(batch),batch[1],batch[0].shape)
print(data.class_names)
class_names = data.class_names

fig, ax = plt.subplots(1,4)
'''
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].set_title(class_names[batch[1][idx]])
'''

# Alternate way to view plots from tensorflow docs
for images, labels in data.take(1):
    for i in range(4):
        ax[i].imshow(images[i].numpy().astype(int))
        ax[i].set_title(class_names[labels[i]])
#print(img.shape)
#plt.imshow(img)

"""SCALE DATA"""

data = data.map(lambda x,y:(x/255,y))

fig, ax = plt.subplots(1,4)
for images, labels in data.take(1):
    for i in range(4):
        ax[i].imshow(images[i].numpy())
        ax[i].set_title(class_names[labels[i]])
plt.show()

data_iter_val = data.as_numpy_iterator()

batch = data_iter_val.next()
print(batch[1])
batch[0].shape

"""SPLIT DATA"""

train_size = int(len(data)*0.7)
val_size = int(len(data)*0.2)
test_size = int(len(data)*0.1)
print(f"Training dataset size: {train_size}\nVal. dataset size: {val_size}\nTest dataset size: {test_size}\nTotal: {len(data)}")
print(f"Total size after splitting: {train_size+test_size+val_size}")
print(f"Was the split right: {train_size+test_size+val_size==len(data)}")

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(test_size)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, AveragePooling2D
from tensorflow.keras.callbacks import ModelCheckpoint

model = Sequential([
  Conv2D(32, 3, activation='relu', input_shape=(60,40,1),padding="same"), # padding is applied
    # Each filter is of dimension 3,3,1
  AveragePooling2D(pool_size=(2,2)), # The maximum value of 2x2 sub-matrix is taken

  Conv2D(32, 3, activation='relu'),
  AveragePooling2D(pool_size=2, padding="valid"),

  Conv2D(32, 3, activation='relu'),
  AveragePooling2D(pool_size=2, padding="valid"),

  Flatten(),
  Dense(62, activation='softmax') # changed to have 62 neurons (same as number of classes) and 'softmax' activation
])

model.summary()

# Define a Callback class that stops training once accuracy reaches 90%
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('acc')>0.90):
      print("\nReached 90% accuracy so cancelling training!")
      self.model.stop_training = True

# Compile the model
model.compile(loss="sparse_categorical_crossentropy", # sparse categorical entropy in case of softmax acti. func.
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

#Fit the model
history = model.fit(train,
                    epochs=10,
                    steps_per_epoch=len(train),
                    validation_data=val,
                    callbacks=[ModelCheckpoint("./models/checkpoints_new/{epoch:02d}.h5",save_best_only=True),
                               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)])

#model_baseline.save("second_try.h5")

"""LOSS & ACCURACY"""

epochs = [*range(1,11)]
plt.style.use(["science","no-latex","grid"])

fig, ax = plt.subplots(1,1,figsize=(9,3))
ax.plot(epochs,history.history["accuracy"])
ax.plot(epochs,history.history["val_accuracy"])
ax.legend(["Accuracy","Validation Accuracy"])
ax.set_title("Accuracy and Validation Accuracy V/s Epochs")
ax.set_xlabel("Epochs")
ax.set_ylabel("Accuracy")
plt.savefig("./models/model_perf/acc_plt.png",dpi=400)
plt.show(); plt.close()

fig, ax = plt.subplots(1,1,figsize=(9,3))
ax.plot(epochs,history.history["loss"])
ax.plot(epochs,history.history["val_loss"])
ax.legend(["Loss","Validation Loss"])
ax.set_title("Loss and Validation Loss V/s Epochs")
ax.set_xlabel("Epochs")
ax.set_ylabel("Loss")
plt.savefig("./models/model_perf/loss_plt.png",dpi=400)
plt.show(); plt.close()

"""EVALUATION"""

from tensorflow.keras.models import load_model

loaded_model = load_model("models/checkpoints_new/09.h5")

eval_data = loaded_model.evaluate(test)

print(eval_data)

# data_iter_val = test.as_numpy_iterator()
# test_batch = data_iter_val.next()
# print(test_batch)
predictions = np.array([])
labels = np.array([])

for x,y in test:
    predictions = np.concatenate([predictions,np.argmax(loaded_model.predict(x),axis=-1)])
    labels = np.concatenate([labels,y.numpy()])

#     print(y.numpy())
#     labels =  np.concatenate([labels,np.argmax(y.numpy(),axis=-1)])

print(predictions,labels)

import seaborn as sns

conf_mat = tf.math.confusion_matrix(labels,predictions)

fig, ax = plt.subplots(figsize=(45,45))
sns.heatmap(conf_mat,ax=ax,annot=True)
ax.set_xticklabels(class_names)
ax.set_yticklabels(class_names)
plt.savefig("./models/conf_matrix_new.png",dpi=400)

"""RANDOM TEST"""

import random

def load_random():
    ranges = [*range(0,1000,1)]
    values = random.choices(ranges,k=62)
    images = list()
    for i in range(len(values)):
        if i<10:
            img = cv2.imread(f"./dataset/{i}/{values[i]}.png")
        else:
            img = cv2.imread(f"./dataset/{class_names[i]}/{class_names[i]}_{values[i]}.png")
        if img is not None:
            images.append(img)
        else:
            if i<10:
                img = cv2.imread(f"./dataset/{i}/1.png")
            else:
                img = cv2.imread(f"./dataset/{class_names[i]}/{class_names[i]}_1.png")
#             while True:
#                 val = values[i]
#                 if i<10:
#                     img = cv2.imread(f"./dataset/{i}/{val+1}.png")
#                 else:
#                     print("whoa")
#                     img = cv2.imread(f"./dataset/{class_names[i]}/{class_names[i]}_{val+1}.png")
#                 if img is not None:
#                     break
#                 else:
#                     val +=1
    return images


def plot_those_imgs(images,**kwargs):
    fig, ax = plt.subplots(8,8,figsize=(16,16))
    fig.tight_layout()
    for i in range(len(images)):
        ax[i//8,i%8].imshow(images[i])
        if len(kwargs)==0:
            ax[i//8,i%8].title.set_text(f"{class_names[i]}")
        else:
            ax[i//8,i%8].title.set_text(f"{class_names[i]} - {kwargs['acc'][i]}")
    plt.show()

while True:
    images = load_random()
    if len(images)==62:
        break
    print(len(images))

plot_those_imgs(images)

plt.close()

resize = tf.image.resize(tf.image.rgb_to_grayscale(images),(60,40))
plot_those_imgs(resize)

yhat = loaded_model.predict(*np.expand_dims(resize/255, 0))
yhat

acc_pred = [f"{round(float(yhat[i][np.argmax(yhat[i])]),2)} - {class_names[np.argmax(yhat[i])]}" for i in range(len(yhat))]
print(acc_pred)
plot_those_imgs(resize,acc=acc_pred)